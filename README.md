## ðŸ“Œ Task 1: AI & ML Internship Assignment
# ðŸš¢ Titanic Dataset - Data Cleaning & Preprocessing

This repository contains my work on data cleaning and preprocessing as part of my AI/ML internship at **Elevate Labs**. The goal was to prepare raw data from the Titanic dataset for machine learning models by applying key preprocessing techniques.

## Objective
Learn and implement essential data preprocessing steps including:
- Handling missing values
- Encoding categorical variables
- Feature scaling
- Outlier detection and removal

## Tools Used
- Python
- Pandas
- NumPy
- Matplotlib
- Seaborn
- Scikit-learn

## Dataset
The dataset used is the [Titanic Dataset](https://www.kaggle.com/datasets/yasserh/titanic-dataset) from Kaggle.

## Preprocessing Steps

1. **Data Exploration**
   - Checked dataset structure, data types, and missing values.

2. **Handling Missing Values**
   - Imputed numerical missing values using median.
   - Filled categorical missing values using mode.
   - Dropped or treated columns with excessive missing data.

3. **Encoding Categorical Features**
   - Applied Label Encoding for binary/ordinal variables.
   - Used One-Hot Encoding for nominal categorical variables.

4. **Feature Scaling**
   - Standardized features using `StandardScaler`.
   - Normalized features using `MinMaxScaler`.

5. **Outlier Detection**
   - Visualized outliers using boxplots.
   - Removed or capped extreme values in important features.

## Visualizations
- Boxplots for detecting outliers.
- Histograms for feature distribution analysis.
- Heatmaps to inspect feature correlations.

## Key Learnings
- Data cleaning is a crucial step for building robust ML models.
- Proper handling of missing values and outliers improves model performance.
- Encoding and scaling prepare data for effective algorithm training.
- Hands-on experience with popular Python data science libraries.

